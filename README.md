# LLM Response Evaluator
I creating a system using **Python** to evaluate the quality of responses generated by Local Language Models (LLMs) by comparing their answers to a trusted source— **Wolfram Alpha**.
The system prompts two different LLMs, which are containerized using Docker, with a set of 50 general knowledge questions.
It records their answers, the time taken to respond, and the correctness of their answers.
Correctness is assessed by comparing the LLMs’ responses to Wolfram Alpha’s answers using another LLM, which rates the similarity on a scale of 0 to 10.
**Redis** is used to implement caching, avoiding redundant calls to the Wolfram Alpha API.
The system outputs the average answer ratings, the lowest-rated responses.
